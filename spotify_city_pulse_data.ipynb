{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f5c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b084f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(s):\n",
    "    # Convert to lowercase\n",
    "    s = s.lower()\n",
    "    # Keep only letters, numbers, commas, ampersands, and spaces using regular expression\n",
    "    s = re.sub(r'[^a-z0-9,& ]', '', s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cb09202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_chart(url, date):\n",
    "    driver.get(url)\n",
    "\n",
    "    # Scrape the chart title (e.g., \"Daily Viral Songs Global\")\n",
    "    chart_title = driver.find_element(By.CSS_SELECTOR, 'h1').text\n",
    "    \n",
    "    # take the first 3 words of chart title text (e.g. \"Daily Viral Songs\")\n",
    "    chart = \" \".join(chart_title.split(\" \")[0:3])\n",
    "    \n",
    "    territory = chart_title.strip()\n",
    "    territory = re.sub(r\"^Local Pulse \", \"\", chart_title)\n",
    "\n",
    "    # Locate the table element using 'data-encore-id'\n",
    "    table_element = driver.find_element(By.CSS_SELECTOR, '[data-encore-id=\"table\"]')\n",
    "\n",
    "    # Extract table rows (assuming table rows are defined using <tr> within the <table>)\n",
    "    rows = table_element.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "    # Initialize list to hold table data\n",
    "    table_data = []\n",
    "\n",
    "    # Iterate over rows and extract song, artist, and other information\n",
    "    for row in rows:\n",
    "\n",
    "        # Extract all cells in the row\n",
    "        cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        \n",
    "        if len(cells) < 2:\n",
    "            continue\n",
    "\n",
    "        rank_and_chg = cells[1].text.split(\"\\n\")  # Split on newline to separate song and artist\n",
    "        if len(rank_and_chg) >= 2:\n",
    "            rank = int(rank_and_chg[0].strip())  # First part is the song title\n",
    "            chg = rank_and_chg[1].strip()  # Second part is the artist name\n",
    "        else:\n",
    "            rank = int(rank_and_chg[0].strip())\n",
    "            chg = ''\n",
    "\n",
    "        subject = cells[2].text if len(cells) > 2 else ''\n",
    "        subject = subject.split(\"\\n\")  # Split on newline to separate song and artist\n",
    "        if len(subject) >= 2:\n",
    "            # NEED TO KEEP ARTIST FIRST SO YOU CAN OVERWRITE SUBJECT AFTER\n",
    "            artist = subject[1].strip()  # Second part is the artist name\n",
    "            subject = subject[0].strip()  # First part is the subject title\n",
    "        else:\n",
    "            # NEED TO KEEP ARTIST FIRST SO YOU CAN OVERWRITE SUBJECT AFTER\n",
    "            artist = subject[0].strip()\n",
    "            subject = ''\n",
    "\n",
    "        # Extract remaining columns\n",
    "        peak = cells[3].text\n",
    "        prev = cells[4].text\n",
    "        streak = cells[5].text\n",
    "        \n",
    "        if chg in ('â€“', 'Re-Entry', 'New'):\n",
    "            pass\n",
    "        elif int(prev) - int(rank) == 0:\n",
    "            pass\n",
    "        elif int(prev) - int(rank) > 0:\n",
    "            chg = f\"+{chg}\"\n",
    "        elif int(prev) - int(rank) < 0:\n",
    "            chg = f\"-{chg}\"\n",
    "        \n",
    "        row_data = [rank, chg, subject, artist, peak, prev, streak, territory, date]\n",
    "        table_data.append(row_data)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(table_data, \n",
    "            columns=[\"Rank\", \"Change\", \"Track\", \"Artist\", \"Peak\", \"Prev\", \"Streak\", \"City\", \"Date\"])\n",
    "\n",
    "    df['Chart'] = 'City Weekly Pulse Songs'\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d', errors='coerce')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67562e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_recent_thursday():\n",
    "    today = datetime.today()\n",
    "    # Calculate how many days to subtract to get the most recent Thursday\n",
    "    days_since_thursday = (today.weekday() - 3) % 7\n",
    "    most_recent_thursday = today - timedelta(days=days_since_thursday + 7)\n",
    "    return most_recent_thursday.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93b6521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [\n",
    "    'anaheim',\n",
    "    'atlanta',\n",
    "    'austin',\n",
    "    'charlotte',\n",
    "    'chicago',\n",
    "    'cleveland',\n",
    "    'dallas',\n",
    "    'denver',\n",
    "    'detroit',\n",
    "    'houston',\n",
    "    'indianapolis',\n",
    "    'lasvegas',\n",
    "    'losangeles',\n",
    "    'memphis',\n",
    "    'miami',\n",
    "    'minneapolis',\n",
    "    'nashville',\n",
    "    'neworleans',\n",
    "    'newyorkcity',\n",
    "    'omaha',\n",
    "    'philadelphia',\n",
    "    'phoenix',\n",
    "    'pittsburgh',\n",
    "    'portland',\n",
    "    'sacramento',\n",
    "    'saltlakecity',\n",
    "    'sanantonio',\n",
    "    'sandiego',\n",
    "    'sanfrancisco',\n",
    "    'sanjuan',\n",
    "    'seattle',\n",
    "    'stlouis',\n",
    "    'tampa',\n",
    "    'washington'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62195100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anaheim\n",
      "atlanta\n",
      "austin\n",
      "charlotte\n",
      "chicago\n",
      "cleveland\n",
      "dallas\n",
      "denver\n",
      "detroit\n",
      "houston\n",
      "indianapolis\n",
      "lasvegas\n",
      "losangeles\n",
      "memphis\n",
      "miami\n",
      "minneapolis\n",
      "nashville\n",
      "neworleans\n",
      "newyorkcity\n",
      "omaha\n",
      "philadelphia\n",
      "phoenix\n",
      "pittsburgh\n",
      "portland\n",
      "sacramento\n",
      "saltlakecity\n",
      "sanantonio\n",
      "sandiego\n",
      "sanfrancisco\n",
      "sanjuan\n",
      "seattle\n",
      "stlouis\n",
      "tampa\n",
      "washington\n"
     ]
    }
   ],
   "source": [
    "chromedriver_path = \"path/to/file\"\n",
    "service = Service(executable_path=chromedriver_path)\n",
    "\n",
    "options = Options()\n",
    "# options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Open the Spotify login page\n",
    "driver.get(\"https://accounts.spotify.com/en/login\")\n",
    "\n",
    "# Maximize window (optional)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Locate the username and password fields and enter your credentials\n",
    "username_field = driver.find_element(By.ID, \"login-username\")\n",
    "password_field = driver.find_element(By.ID, \"login-password\")\n",
    "\n",
    "username_field.send_keys(\"enter username\")\n",
    "password_field.send_keys(\"enter password\")\n",
    "\n",
    "login_button = driver.find_element(By.ID, \"login-button\")\n",
    "login_button.click()\n",
    "\n",
    "driver.implicitly_wait(10)\n",
    "time.sleep(10)\n",
    "\n",
    "all_cities_df = pd.DataFrame()\n",
    "\n",
    "url = \"https://charts.spotify.com/charts/view/citypulsetrack\"\n",
    "date = get_most_recent_thursday()\n",
    "for city in cities:\n",
    "    print(city)\n",
    "    city_url = url + f\"-{city}-weekly/{date}\"\n",
    "    df = scrape_chart(city_url, date)\n",
    "    all_cities_df = pd.concat([all_cities_df, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aee98ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file = \"path/to/file\"\n",
    "\n",
    "all_cities_df.to_csv(download_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab03ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
